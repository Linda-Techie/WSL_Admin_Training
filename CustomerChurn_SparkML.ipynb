{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Validate our Environment\n",
    "\n",
    "**Check Python version. This notebook is implemented for Python 3.5.x. Not all cells may work in other versions of Python.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.5\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Predicting Customer Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this notebook you will learn how to build a predictive model with Spark machine learning API (SparkML) and deploy it for scoring in Machine Learning (ML). \n",
    "\n",
    "This notebook walks you through these steps:\n",
    "- Build a model with SparkML API\n",
    "- Save the model in the ML repository\n",
    "- Create a Deployment in ML (via UI)\n",
    "- Test the model (via UI)\n",
    "- Test the model (via REST API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 1: Review Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The analytics use case implemented in this notebook is telco churn. While it's a simple use case, it implements all steps from the CRISP-DM methodolody, which is the recommended best practice for implementing predictive analytics. \n",
    "![CRISP-DM](https://raw.githubusercontent.com/yfphoon/dsx_demo/master/crisp_dm.png)\n",
    "\n",
    "The analytics process starts with defining the business problem and identifying the data that can be used to solve the problem. For Telco churn, we use demographic and historical transaction data. We also know which customers have churned, which is the critical information for building predictive models. In the next step, we use visual APIs for data understanding and complete some data preparation tasks. In a typical analytics project data preparation will include more steps (for example, formatting data or deriving new variables). \n",
    "\n",
    "Once the data is ready, we can build a predictive model. In our example we are using the SparkML Random Forrest classification model. Classification is a statistical technique which assigns a \"class\" to each customer record (for our use case \"churn\" or \"no churn\"). Classification models use historical data to come up with the logic to predict \"class\", this process is called model training. After the model is created, it's usually evaluated using another data set. \n",
    "\n",
    "Finally, if the model's accuracy meets the expectations, it can be deployed for scoring. Scoring is the process of applying the model to a new set of data. For example, when we receive new transactional data, we can score the customer for the risk of churn.  \n",
    "\n",
    "We also developed a sample Python Flask application to illustrate deployment: http://predictcustomerchurn.mybluemix.net/. This application implements the REST client call to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prerequisite:  Upgrade Pixiedust and dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## **<span style=\"color:red\"> Action Required </span>** \n",
    "** Restart Kernel after Pixiedust Upgrade **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pixiedust in /user-home/1001/.local/lib/python3.5/site-packages (1.1.15)\n",
      "Requirement already up-to-date: py4j in /user-home/1001/.local/lib/python3.5/site-packages (0.10.8.1)\n",
      "Requirement already up-to-date: jinja2 in /opt/conda3/lib/python3.5/site-packages (2.10)\n",
      "Requirement already up-to-date: pandas in /user-home/1001/.local/lib/python3.5/site-packages (0.24.1)\n",
      "Requirement already satisfied, skipping upgrade: astunparse in /opt/conda3/lib/python3.5/site-packages (from pixiedust) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: lxml in /opt/conda3/lib/python3.5/site-packages (from pixiedust) (4.2.3)\n",
      "Requirement already satisfied, skipping upgrade: colour in /opt/conda3/lib/python3.5/site-packages (from pixiedust) (0.1.5)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda3/lib/python3.5/site-packages (from pixiedust) (2.18.4)\n",
      "Requirement already satisfied, skipping upgrade: markdown in /opt/conda3/site-packages (from pixiedust) (2.6.11)\n",
      "Requirement already satisfied, skipping upgrade: mpld3 in /opt/conda3/lib/python3.5/site-packages (from pixiedust) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: geojson in /opt/conda3/lib/python3.5/site-packages (from pixiedust) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda3/lib/python3.5/site-packages (from jinja2) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /opt/conda3/lib/python3.5/site-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /opt/conda3/lib/python3.5/site-packages (from pandas) (2016.6.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /opt/conda3/lib/python3.5/site-packages (from pandas) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: wheel<1.0,>=0.23.0 in /opt/conda3/lib/python3.5/site-packages (from astunparse->pixiedust) (0.31.1)\n",
      "Requirement already satisfied, skipping upgrade: six<2.0,>=1.6.1 in /opt/conda3/lib/python3.5/site-packages (from astunparse->pixiedust) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda3/lib/python3.5/site-packages (from requests->pixiedust) (2018.4.16)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /opt/conda3/lib/python3.5/site-packages (from requests->pixiedust) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda3/lib/python3.5/site-packages (from requests->pixiedust) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /opt/conda3/lib/python3.5/site-packages (from requests->pixiedust) (1.22)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade pixiedust py4j jinja2 pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![RESTART KERNEL](https://raw.githubusercontent.com/krondor/ICP4D-/master/pics/restart_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Working with Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you are new to Notebooks, here's a quick overview of how to work in this environment.\n",
    "\n",
    "1. The notebook has 2 types of cells - markdown (text) and code. \n",
    "2. Each cell with code can be executed independently or together (see options under the Cell menu). When working in this notebook, we will be running one cell at a time because we need to make code changes to some of the cells.\n",
    "3. To run the cell, position cursor in the code cell and click the Run (arrow) icon. The cell is running when you see the * next to it. Some cells have printable output.\n",
    "4. Work through this notebook by reading the instructions and executing code cell by cell. Some cells will require modifications before you run them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 2: Load customer HDFS dataset via remote Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Hadoop systems: \n",
      "\n",
      "  systemName  LIVYSPARK  LIVYSPARK2 imageId\n",
      "0     hdp263  livyspark  livyspark2        \n",
      "1     hdp265  livyspark  livyspark2        \n"
     ]
    }
   ],
   "source": [
    "import dsx_core_utils\n",
    "%load_ext sparkmagic.magics\n",
    "\n",
    "# Retrieve a list of registered Hadoop Integration systems.\n",
    "DSXHI_SYSTEMS = dsx_core_utils.get_dsxhi_info(showSummary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparkmagic has been configured to use https://hdp263-wsl5.fyre.ibm.com:8443/gateway/9.30.182.106/livy2/v1 \n",
      "success configuring sparkmagic livy.\n"
     ]
    }
   ],
   "source": [
    "# Set up sparkmagic to connect to the selected registered HI systemName above.\n",
    "myConfig={\n",
    "    \"queue\": \"default\",\n",
    "    \"driverMemory\": \"512M\",\n",
    "    \"numExecutors\": 1,\n",
    "    \"executorMemory\":\"512M\"\n",
    "}\n",
    "\n",
    "HI_CONFIG = dsx_core_utils.setup_livy_sparkmagic(\n",
    "  system=\"hdp263\", \n",
    "  livy=\"livyspark2\",\n",
    "  imageId=None,\n",
    "  addlConfig=myConfig)\n",
    "\n",
    "# (Re-)load spark magic to apply the new configs.\n",
    "%reload_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>12</td><td>application_1549042673081_0016</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hdp263-wsl2.fyre.ibm.com:8088/proxy/application_1549042673081_0016/\">Link</a></td><td><a target=\"_blank\" href=\"http://hdp263-wsl5.fyre.ibm.com:8042/node/containerlogs/container_e02_1549042673081_0016_01_000001/dsxhi\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%spark cleanup\n",
    "session_name = 'spark2_0205'\n",
    "livy_endpoint = HI_CONFIG['LIVY']\n",
    "webhdfs_endpoint = HI_CONFIG['WEBHDFS']\n",
    "%spark add -s $session_name -l python -u $livy_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info for running Spark:\n",
      "    Sessions:\n",
      "        Name: spark2_0205\tSession id: 12\tYARN id: application_1549042673081_0016\tKind: pyspark\tState: idle\n",
      "\tSpark UI: http://hdp263-wsl2.fyre.ibm.com:8088/proxy/application_1549042673081_0016/\n",
      "\tDriver Log: http://hdp263-wsl5.fyre.ibm.com:8042/node/containerlogs/container_e02_1549042673081_0016_01_000001/dsxhi\n",
      "    Session configs:\n",
      "        {'queue': 'default', 'conf': {'spark.yarn.appMasterEnv.HI_UTILS_PATH': '/user/dsxhi/environments/pythonAddons/hi_core_utils.zip'}, 'proxyUser': 'dsxhi', 'numExecutors': 1, 'executorMemory': '512M', 'driverMemory': '512M'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%spark info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote livy session driver: hdp263-wsl4.fyre.ibm.com"
     ]
    }
   ],
   "source": [
    "%%spark -s $session_name\n",
    "import socket\n",
    "print(\"Remote livy session driver: {}\".format(socket.gethostname()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'2.2.0.2.6.3.0-235'"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "      <td>del2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>default</td>\n",
       "      <td>ext_customer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>default</td>\n",
       "      <td>out_0208</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  database     tableName  isTemporary\n",
       "0  default          del2        False\n",
       "1  default  ext_customer        False\n",
       "2  default      out_0208        False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -s $session_name -c sql\n",
    "show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PHASE: string (nullable = true)\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- LONGDISTANCE: integer (nullable = true)\n",
      " |-- INTERNATIONAL: integer (nullable = true)\n",
      " |-- LOCAL: integer (nullable = true)\n",
      " |-- DROPPED: integer (nullable = true)\n",
      " |-- PAYMETHOD: string (nullable = true)\n",
      " |-- LOCALBILLTYPE: string (nullable = true)\n",
      " |-- LONGDISTANCEBILLTYPE: string (nullable = true)\n",
      " |-- USAGE: integer (nullable = true)\n",
      " |-- RATEPLAN: integer (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- STATUS: string (nullable = true)\n",
      " |-- CHILDREN: integer (nullable = true)\n",
      " |-- ESTINCOME: double (nullable = true)\n",
      " |-- CAROWNER: string (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      "\n",
      "Total number of customer dataset row count: 2066"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "file_customer = \"hdfs:///data/demo/customer/enhanced_customer.csv\"\n",
    "df_cust = spark.read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(file_customer)\n",
    "df_cust.printSchema()\n",
    "\n",
    "print(\"Total number of customer dataset row count: {}\\n\".format(df_cust.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### <font color=\"blue\">B. </font> Load customer churn HDFS dataset via remote Spark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- CHURN: string (nullable = true)\n",
      "\n",
      "Total number of churn dataset row count: 2066"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "file_churn = \"hdfs:///data/demo/churn/churn.csv\"\n",
    "df_churn = spark.read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(file_churn)\n",
    "df_churn.printSchema()\n",
    "\n",
    "print(\"Total number of churn dataset row count: {}\\n\".format(df_churn.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If the first step ran successfully (you saw the output), then continue reviewing the notebook and running each code cell step by step. Note that not every cell has a visual output. The cell is still running if you see a * in the brackets next to the cell. \n",
    "\n",
    "If the first step didn't finish successfully, check with the instructor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 3: Merge Files\n",
    "While merging files, making sure that you are using the remote connected data - customer(df1 or other version) and churn data. The name of the enhanced customer data table may be different. You should make sure that the name is consistent with the name when importing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customer and churn combined dataset row count: 2066"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_data = df_cust.join(df_churn,df_cust['ID']==df_churn['ID']).select(df_cust['*'],df_churn['CHURN'])\n",
    "\n",
    "print(\"Total number of customer and churn combined dataset row count: {}\\n\".format(df_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 4: Data Prep\n",
    "A typical data scientist workflow may involve lots of data prep.  This is a simple example of this process, we can rename columns, define data types, or otherwise manipulate data elements.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Schema Data Type Transformation \n",
    "# Change data type example:\n",
    "#data = data.withColumn('ID', data['ID'].cast('int'))\n",
    "#data = data.withColumn('USAGE', data['USAGE'].cast('Decimal(5,0)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 5: Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Data preparation and data understanding are the most time-consuming tasks in the data mining process. The data scientist needs to review and evaluate the quality of data before modeling.\n",
    "\n",
    "Visualization is one of the ways to reivew data.\n",
    "\n",
    "The Brunel Visualization Language is a highly succinct and novel language that defines interactive data visualizations based on tabular data. The language is well suited for both data scientists and business users. \n",
    "More information about Brunel Visualization: https://github.com/Brunel-Visualization/Brunel/wiki\n",
    "\n",
    "Try Brunel visualization here: http://brunel.mybluemix.net/gallery_app/renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark -s $session_name -o data\n",
    "data = df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2066 entries, 0 to 2065\n",
      "Data columns (total 18 columns):\n",
      "PHASE                   2066 non-null object\n",
      "ID                      2066 non-null int64\n",
      "LONGDISTANCE            2066 non-null int64\n",
      "INTERNATIONAL           2066 non-null int64\n",
      "LOCAL                   2066 non-null int64\n",
      "DROPPED                 2066 non-null int64\n",
      "PAYMETHOD               2066 non-null object\n",
      "LOCALBILLTYPE           2066 non-null object\n",
      "LONGDISTANCEBILLTYPE    2066 non-null object\n",
      "USAGE                   2066 non-null int64\n",
      "RATEPLAN                2066 non-null int64\n",
      "GENDER                  2066 non-null object\n",
      "STATUS                  2066 non-null object\n",
      "CHILDREN                2066 non-null int64\n",
      "ESTINCOME               2066 non-null float64\n",
      "CAROWNER                2066 non-null object\n",
      "AGE                     2066 non-null float64\n",
      "CHURN                   2066 non-null object\n",
      "dtypes: float64(2), int64(8), object(8)\n",
      "memory usage: 290.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/autovizwidget/widget/utils.py:50: FutureWarning:\n",
      "\n",
      "A future version of pandas will default to `skipna=True`. To silence this warning, pass `skipna=True|False` explicitly.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8364d899bd46ff8c7b98afafe7e2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='Type:'), Button(description='Table', layout=Layout(width='70px'), st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7923c2cc0e6a4edc8a7fab467abc519d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655e5e5063cf4ac388619a1421722909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AutoVizWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from autovizwidget.widget.utils import display_dataframe\n",
    "display_dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "pixiedust": {
     "displayParams": {
      "aggregation": "AVG",
      "handlerId": "barChart",
      "keyFields": "CHURN",
      "valueFields": "USAGE"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n",
       "        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n",
       "            \n",
       "        </div>\n",
       "    <div id=\"chartFigureadd068de\" class=\"pd_save is-viewer-good\" style=\"overflow-x:auto\">\n",
       "            \n",
       "                    \n",
       "                            <center><img style=\"max-width:initial !important\" src=\"data:image/png;base64,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\" class=\"pd_save\"></center>\n",
       "                        \n",
       "                    \n",
       "                \n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pixiedust.display import *\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 6: Build the Spark pipeline and the Random Forest model\n",
    "\"Pipeline\" is an API in SparkML that's used for building models.\n",
    "Additional information on SparkML: https://spark.apache.org/docs/2.0.2/ml-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[PHASE: string, ID: int, LONGDISTANCE: int, INTERNATIONAL: int, LOCAL: int, DROPPED: int, PAYMETHOD: string, LOCALBILLTYPE: string, LONGDISTANCEBILLTYPE: string, USAGE: int, RATEPLAN: int, GENDER: string, STATUS: string, CHILDREN: int, ESTINCOME: double, CAROWNER: string, AGE: double, CHURN: string, GenderEncoded: double, StatusEncoded: double, CarOwnerEncoded: double, PaymethodEncoded: double, LocalBilltypeEncoded: double, LongDistanceBilltypeEncoded: double, PhaseEncoded: double, label: double, features: vector, rawPrediction: vector, probability: vector, prediction: double, predictedLabel: string]"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, IndexToString\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "import numpy\n",
    "\n",
    "# Prepare string variables so that they can be used by the decision tree algorithm\n",
    "# StringIndexer encodes a string column of labels to a column of label indices\n",
    "SI1 = StringIndexer(inputCol='GENDER', outputCol='GenderEncoded')\n",
    "SI2 = StringIndexer(inputCol='STATUS',outputCol='StatusEncoded')\n",
    "SI3 = StringIndexer(inputCol='CAROWNER',outputCol='CarOwnerEncoded')\n",
    "SI4 = StringIndexer(inputCol='PAYMETHOD',outputCol='PaymethodEncoded')\n",
    "SI5 = StringIndexer(inputCol='LOCALBILLTYPE',outputCol='LocalBilltypeEncoded')\n",
    "SI6 = StringIndexer(inputCol='LONGDISTANCEBILLTYPE',outputCol='LongDistanceBilltypeEncoded')\n",
    "SI7 = StringIndexer(inputCol='PHASE',outputCol='PhaseEncoded')\n",
    "labelIndexer = StringIndexer(inputCol='CHURN', outputCol='label').fit(df_data)\n",
    "\n",
    "# Pipelines API requires that input variables are passed in  a vector\n",
    "assembler = VectorAssembler(inputCols=[\"GenderEncoded\", \"StatusEncoded\", \"CarOwnerEncoded\", \"PaymethodEncoded\", \"LocalBilltypeEncoded\", \\\n",
    "                                       \"LongDistanceBilltypeEncoded\", \"PhaseEncoded\", \"CHILDREN\", \"ESTINCOME\", \"AGE\", \"LONGDISTANCE\", \"INTERNATIONAL\", \"LOCAL\",\\\n",
    "                                      \"DROPPED\",\"USAGE\",\"RATEPLAN\"], outputCol=\"features\")\n",
    "\n",
    "# instantiate the algorithm, take the default settings\n",
    "rf=RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
    "\n",
    "pipeline = Pipeline(stages=[SI1,SI2,SI3,SI4,SI5,SI6,SI7,labelIndexer, assembler, rf, labelConverter])\n",
    "\n",
    "# Split data into train and test datasets\n",
    "train, test = df_data.randomSplit([0.7,0.3], seed=6)\n",
    "train.cache()\n",
    "test.cache()\n",
    "\n",
    "# Build models\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>"
     ]
    }
   ],
   "source": [
    "%%spark -s $session_name -o test_local\n",
    "test_local = test\n",
    "print(type(test))\n",
    "print(type(test_local))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 7: Score the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+--------------+----------+--------------------+\n",
      "| ID|CHURN|label|predictedLabel|prediction|         probability|\n",
      "+---+-----+-----+--------------+----------+--------------------+\n",
      "|  6|    F|  0.0|             F|       0.0|[0.89564720115218...|\n",
      "| 14|    F|  0.0|             F|       0.0|[0.94814005265572...|\n",
      "| 18|    F|  0.0|             F|       0.0|[0.81772150065880...|\n",
      "| 21|    F|  0.0|             F|       0.0|[0.58192994876721...|\n",
      "| 22|    F|  0.0|             F|       0.0|[0.64440750619622...|\n",
      "| 35|    T|  1.0|             F|       0.0|[0.58831793453656...|\n",
      "+---+-----+-----+--------------+----------+--------------------+\n",
      "only showing top 6 rows"
     ]
    }
   ],
   "source": [
    "%%spark -s $session_name\n",
    "\n",
    "results = model.transform(test)\n",
    "results=results.select(results[\"ID\"],results[\"CHURN\"],results[\"label\"],results[\"predictedLabel\"],results[\"prediction\"],results[\"probability\"])\n",
    "results.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 8: Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision model = 0.89.\n",
      "Area under ROC curve = 0.88."
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "print('Precision model = {:.2f}.'.format(results.filter(results.label == results.prediction).count() / float(results.count())))\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "print('Area under ROC curve = {:.2f}.'.format(evaluator.evaluate(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have finished building and testing a predictive model. The next step is to deploy it for real time scoring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 9: Save Model in ML repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'hdfs:///user/dsxhi/.dsxhi/models/churn_model_02082019/1/model', 'version': 1, 'name': 'churn_model_02082019', 'latest_version': 1}"
     ]
    }
   ],
   "source": [
    "%%spark -s $session_name\n",
    "\n",
    "import os\n",
    "hi_utils_lib = os.getenv(\"HI_UTILS_PATH\", \"/user/dsxhi/environments/pythonAddons/hi_core_utils.zip\")\n",
    "sc.addPyFile(\"hdfs://{}\".format(hi_utils_lib))\n",
    "\n",
    "import hi_core_utils\n",
    "print(hi_core_utils.write_model_to_hdfs(model=model, model_name='churn_model_02082019'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hdp263-wsl5.fyre.ibm.com:8443/gateway/9.30.182.106/webhdfs/v1\n",
      "Model loaded from hdfs:///user/dsxhi/.dsxhi/models/churn_model_02082019/1/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(webhdfs_endpoint)\n",
    "model_local = dsx_core_utils.load_model_from_hdfs(webhdfs_endpoint, model_name=\"churn_model_02082019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHASE</th>\n",
       "      <th>ID</th>\n",
       "      <th>LONGDISTANCE</th>\n",
       "      <th>INTERNATIONAL</th>\n",
       "      <th>LOCAL</th>\n",
       "      <th>DROPPED</th>\n",
       "      <th>PAYMETHOD</th>\n",
       "      <th>LOCALBILLTYPE</th>\n",
       "      <th>LONGDISTANCEBILLTYPE</th>\n",
       "      <th>USAGE</th>\n",
       "      <th>RATEPLAN</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>ESTINCOME</th>\n",
       "      <th>CAROWNER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CHURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>FreeLocal</td>\n",
       "      <td>Standard</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>29616.0</td>\n",
       "      <td>N</td>\n",
       "      <td>49.426667</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Intnl_discount</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>52004.8</td>\n",
       "      <td>N</td>\n",
       "      <td>25.140000</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>CC</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Intnl_discount</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>75004.5</td>\n",
       "      <td>N</td>\n",
       "      <td>64.800000</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>CC</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Standard</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>19749.3</td>\n",
       "      <td>N</td>\n",
       "      <td>60.366667</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>CC</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Standard</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>57626.9</td>\n",
       "      <td>Y</td>\n",
       "      <td>43.906667</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PHASE  ID  LONGDISTANCE  INTERNATIONAL  LOCAL  DROPPED PAYMETHOD  \\\n",
       "0  Adult   6            29              0     45        0        CH   \n",
       "1  Adult  14             5              0     23        0        CH   \n",
       "2  Adult  18            26              0     32        0        CC   \n",
       "3  Adult  21            20              0     13        0        CC   \n",
       "4  Adult  22             9              0     38        0        CC   \n",
       "\n",
       "  LOCALBILLTYPE LONGDISTANCEBILLTYPE  USAGE  RATEPLAN GENDER STATUS  CHILDREN  \\\n",
       "0     FreeLocal             Standard     75         2      M      M         2   \n",
       "1        Budget       Intnl_discount     28         1      F      M         2   \n",
       "2        Budget       Intnl_discount     58         1      M      M         1   \n",
       "3        Budget             Standard     34         3      M      M         0   \n",
       "4        Budget             Standard     48         2      M      S         1   \n",
       "\n",
       "   ESTINCOME CAROWNER        AGE CHURN  \n",
       "0    29616.0        N  49.426667     F  \n",
       "1    52004.8        N  25.140000     F  \n",
       "2    75004.5        N  64.800000     F  \n",
       "3    19749.3        N  60.366667     F  \n",
       "4    57626.9        Y  43.906667     F  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_local))\n",
    "test_local.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = spark.createDataFrame(test_local)\n",
    "type(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'path': '/user-home/1001/DSX_Projects/ThinkConf_ML/models/churn_model_02082019/1',\n",
       " 'scoring_endpoint': 'https://dsxl-api/v3/project/score/Python35/spark-2.2/ThinkConf_ML/churn_model_02082019/1'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dsx_ml.ml import save\n",
    "\n",
    "model_name = 'churn_model_02082019'\n",
    "save(name = model_name,\n",
    "     model = model_local,\n",
    "     algorithm_type = 'Classification',\n",
    "     test_data = df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 10: Test Saved Model with Test UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1. Save the notebook and select **Project** --> **Assets** --> **Models** \n",
    "2. Under **Models**, find and click into your saved model. \n",
    "4. Click the **Real-time Score** tab to test the model. You can use the following data for testing: <br/>\n",
    "`Phase='Adult', ID=99, LongDistance=68, International=50, Local=100, Dropped=0, Paymethod=CC, LocalBilltype=Budget, LongDistanceBilltype=Intnl_discount, Usage=334, RatePlan=3, Gender=M, Status=S, Chidren=0, EstIncome=60000, CarOwner=Y, Age=34`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The results of the test is displayed as follows:<br/>\n",
    "<img style=\"float: left;\" src=\"https://github.com/Linda-Techie/ThinkConf_2019/blob/master/img/model_testing.png?raw=true\" alt=\"Test API\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 11:  Test model with a REST API call (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This step demonstrates an \"internal REST API\" call to test the model (for an unpublished model). Notice that we are using DSX variables for the model endpoint and token. See documentation for external REST call syntax. An exernal REST call will have a different end point and will require authentication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "json_payload = [{\n",
    "    \"PHASE\":\"Adult\",\n",
    "    \"ID\":999,\n",
    "    \"GENDER\":\"F\",\n",
    "    \"STATUS\":\"M\",\n",
    "    \"CHILDREN\":2.0,\n",
    "    \"ESTINCOME\":77551.100000,\n",
    "    \"CAROWNER\":\"Y\",\n",
    "    \"AGE\":33,\n",
    "    \"LONGDISTANCE\":20.530000,\n",
    "    \"INTERNATIONAL\":0.000000,\n",
    "    \"LOCAL\":41.890000,\n",
    "    \"DROPPED\":1.000000,\n",
    "    \"PAYMETHOD\":\"CC\",\n",
    "    \"LOCALBILLTYPE\":\"Budget\",\n",
    "    \"LONGDISTANCEBILLTYPE\":\"Standard\",\n",
    "    \"USAGE\":62.420000,\n",
    "    \"RATEPLAN\":2.000000\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## **<span style=\"color:red\"> Action Required </span>** \n",
    "Change the *scoring_endpoint* to the value that's shown as the *scoring_endpoint* afer running Save to ML repository function (see **Step 9**), for example *'scoring_endpoint': 'https://dsxl-api/v3/project/score/Python35/spark-2.2/ThinkConf_ML/churn_model_01312019/2'*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from pprint import pprint\n",
    "\n",
    "#scoring_endpoint = 'https://dsxl-api/v3/project/score/Python35/spark-2.2/ThinkConf_ML/Customer_Churn_ML_model_LL/1'\n",
    "scoring_endpoint = 'https://dsxl-api/v3/project/score/Python35/spark-2.2/ThinkConf_ML/churn_model_02082019/1'\n",
    "        \n",
    "header_online = {'Content-Type': 'application/json', 'Authorization':os.environ['DSX_TOKEN']}\n",
    "\n",
    "response_scoring = requests.post(scoring_endpoint, json=json_payload, headers=header_online)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction = F\n",
      "Probabilities = [0.8975438748792557, 0.1024561251207442]\n",
      "Prediction = False\n",
      "Probability = 89.75\n"
     ]
    }
   ],
   "source": [
    "prediction = response_scoring.json()['object']['output']['predictions'][0]\n",
    "print ('Prediction = {}'.format(prediction))\n",
    "probabilities = response_scoring.json()['object']['output']['probabilities'][0]\n",
    "print ('Probabilities = {}'.format(probabilities))\n",
    "if prediction == 'F':\n",
    "    print('Prediction = False')\n",
    "    print('Probability = {0:.2f}'.format(probabilities[0]*100))\n",
    "elif prediction == 'T':\n",
    "    print('Prediction = True')\n",
    "    print('Probability = {0:.2f}%'.format(probabilities[1]*100))\n",
    "else:\n",
    "    print('Probability ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You have finished working on this hands-on lab. In this notebook you created a model using SparkML API, deployed it in  Machine Learning service for online (real time) scoring and tested it using a test client. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<b>Created by</b> **Sidney Phoon**, **Elena Lowery** and **Rui Fan**\n",
    "<br/>\n",
    "yfphoon@us.ibm.com<br/>\n",
    "elowery@us.ibm.com<br/>\n",
    "rui.fan@ibm.com\n",
    "Created Date: May29, 2018\n",
    "\n",
    "<b>Modified by</b> **Vish Kamat** and **Linda Liu**\n",
    "<br/>\n",
    "vkamat@us.ibm.com<br/>\n",
    "linda.liu@us.ibm.com<br/>\n",
    "Modified Date: Jan. 23, 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%spark cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.session.delete();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.5 with Watson Studio Spark 2.2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
